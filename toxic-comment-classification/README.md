# Классификация токсичных комментариев

## Стек

- EDA: `Matplotlib`, `pandas`, `seaborn`<br>
- Подготовка данных и обучение моделей: `CatBoost`, `Datasets`, `Evaluate`, `NumPy`, `PyTorch`, `scikit-learn`, `Transformers`

## Задача

Построить модель для классификации токсичных комментариев пользователей к описаниям товаров интернет-магазина.

На основании предсказаний модели токсичные комментарии будут отправляться на модерацию. 

Модель дожна демонстрировать качество прогноза `F1` не ниже 0.75.

## Предоставленные данные

Набор комментариев с разметкой их токсичности.

Согласно описанию к данным:

- столбец `text` — текст комментария;
- столбец `toxic` — указание на токсичность (целевой признак).

## Основные этапы работы

Работа над задачей включала пять этапов:

1. загрузка и изучение данных;
2. подготовка к обучению;
3. обучение моделей;
4. анализ моделей; и
5. выбор и тестирование лучшей модели.

## Результат работы

По результатам работы заказчику была предложена модель `DistilBertForSequenceClassification`, которая показала на тестовой выборке значение `F1` (0.85), что на 13% лучше целевого значения.
